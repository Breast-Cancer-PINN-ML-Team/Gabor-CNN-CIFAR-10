{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from skimage.filters import gabor_kernel\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "if K.backend()=='tensorflow':\n",
    "    K.set_image_dim_ordering(\"tf\")\n",
    "from skimage.color import rgb2gray\n",
    "from scipy import ndimage as ndi\n",
    " \n",
    "# Import Tensorflow with multiprocessing\n",
    "import tensorflow as tf\n",
    "import multiprocessing as mp\n",
    " \n",
    "# Loading the CIFAR-10 datasets\n",
    "from keras.datasets import cifar10\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "# 32 examples in a mini-batch, smaller batch size means more updates in one epoch\n",
    "num_classes = 10\n",
    "epochs = 24\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(8,3))\n",
    "# for i in range(num_classes):\n",
    "#     ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "#     idx = np.where(y_train[:]==i)[0]\n",
    "#     features_idx = x_train[idx,::]\n",
    "#     img_num = np.random.randint(features_idx.shape[0])\n",
    "#     im = features_idx[img_num,::]\n",
    "#     ax.set_title(class_names[i])\n",
    "#     plt.imshow(im)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dimension(data):\n",
    "    data = np.array([data])\n",
    "    data = np.einsum('hijk->ijkh', data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(data, dtype='float32'):\n",
    "    # luma coding weighted average in video systems\n",
    "    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\n",
    "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\n",
    "    rst = add_dimension(rst)\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling = 50000\n",
    "x_train = grayscale(x_train.astype('float32')[:sampling])\n",
    "y_train = np_utils.to_categorical(y_train[:sampling], num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "x_test = grayscale(x_test.astype('float32'))\n",
    "x_train  /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(48, (3, 3), padding='same', data_format='channels_last', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(48, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    # sgd = SGD(lr = 0.1, decay = 1e-6, momentum=0.9, nesterov=True)\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "    # Train model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 48)        480       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 48)        20784     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 30, 48)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 15, 15, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 15, 64)        27712     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,271,194\n",
      "Trainable params: 1,271,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/24\n",
      "50000/50000 [==============================] - 297s 6ms/step - loss: 1.8900 - acc: 0.3107 - val_loss: 1.5957 - val_acc: 0.4313\n",
      "Epoch 2/24\n",
      "50000/50000 [==============================] - 276s 6ms/step - loss: 1.5471 - acc: 0.4555 - val_loss: 1.5109 - val_acc: 0.4635\n",
      "Epoch 3/24\n",
      "50000/50000 [==============================] - 278s 6ms/step - loss: 1.3823 - acc: 0.5169 - val_loss: 1.4800 - val_acc: 0.4780\n",
      "Epoch 4/24\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 1.2677 - acc: 0.5614 - val_loss: 1.2043 - val_acc: 0.5780\n",
      "Epoch 5/24\n",
      "50000/50000 [==============================] - 291s 6ms/step - loss: 1.1787 - acc: 0.5913 - val_loss: 1.0855 - val_acc: 0.6203\n",
      "Epoch 6/24\n",
      "50000/50000 [==============================] - 293s 6ms/step - loss: 1.1073 - acc: 0.6192 - val_loss: 1.1389 - val_acc: 0.6100\n",
      "Epoch 7/24\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 1.0510 - acc: 0.6392 - val_loss: 1.0298 - val_acc: 0.6506\n",
      "Epoch 8/24\n",
      "50000/50000 [==============================] - 277s 6ms/step - loss: 1.0027 - acc: 0.6550 - val_loss: 0.9857 - val_acc: 0.6632\n",
      "Epoch 9/24\n",
      "50000/50000 [==============================] - 255s 5ms/step - loss: 0.9652 - acc: 0.6682 - val_loss: 0.9135 - val_acc: 0.6864\n",
      "Epoch 10/24\n",
      "37005/50000 [=====================>........] - ETA: 1:08 - loss: 0.9344 - acc: 0.6799"
     ]
    }
   ],
   "source": [
    "# print(x_train.shape[1:])\n",
    "\n",
    "model = base_model()\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"models/baseline.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save(\"models/baseline.h5\")\n",
    "pickle.dump(history.history, open('history/baseline.p','w'))\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Plots for training and testing process: loss and accuracy\n",
    "\n",
    "# plt.figure(0)\n",
    "# plt.plot(cnn.history['acc'],'r')\n",
    "# plt.plot(cnn.history['val_acc'],'g')\n",
    "# plt.xticks(np.arange(0, epochs, 2.0))\n",
    "# plt.rcParams['figure.figsize'] = (8, 6)\n",
    "# plt.xlabel(\"Num of Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
    "# plt.legend(['train','validation'])\n",
    "\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.plot(cnn.history['loss'],'r')\n",
    "# plt.plot(cnn.history['val_loss'],'g')\n",
    "# plt.xticks(np.arange(0, epochs, 2.0))\n",
    "# plt.rcParams['figure.figsize'] = (8, 6)\n",
    "# plt.xlabel(\"Num of Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.title(\"Training Loss vs Validation Loss\")\n",
    "# plt.legend(['train','validation'])\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
