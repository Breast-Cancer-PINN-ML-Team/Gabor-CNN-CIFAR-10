{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from skimage.filters import gabor_kernel\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "if K.backend()=='tensorflow':\n",
    "    K.set_image_dim_ordering(\"tf\")\n",
    "from skimage.color import rgb2gray\n",
    "from scipy import ndimage as ndi\n",
    " \n",
    "# Import Tensorflow with multiprocessing\n",
    "import tensorflow as tf\n",
    "import multiprocessing as mp\n",
    " \n",
    "# Loading the CIFAR-10 datasets\n",
    "from keras.datasets import cifar10\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "# 32 examples in a mini-batch, smaller batch size means more updates in one epoch\n",
    "num_classes = 10\n",
    "epochs = 24\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(8,3))\n",
    "# for i in range(num_classes):\n",
    "#     ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "#     idx = np.where(y_train[:]==i)[0]\n",
    "#     features_idx = x_train[idx,::]\n",
    "#     img_num = np.random.randint(features_idx.shape[0])\n",
    "#     im = features_idx[img_num,::]\n",
    "#     ax.set_title(class_names[i])\n",
    "#     plt.imshow(im)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling = 10\n",
    "x_train = x_train.astype('float32')[:sampling]\n",
    "y_train = np_utils.to_categorical(y_train[:sampling], num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "x_test = x_test.astype('float32')\n",
    "x_train  /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(48, (3, 3), padding='same', data_format='channels_last', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    # sgd = SGD(lr = 0.1, decay = 1e-6, momentum=0.9, nesterov=True)\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "    # Train model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3, 48)\n",
      "here\n",
      "Tensor(\"conv2d_9/random_normal:0\", shape=(3, 3, 3, 48), dtype=float32)\n",
      "(3, 3, 3, 48)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 48)        624       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        13856     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,255,194\n",
      "Trainable params: 1,255,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10 samples, validate on 10000 samples\n",
      "Epoch 1/24\n",
      "10/10 [==============================] - 13s 1s/step - loss: 5.6683 - acc: 0.1000 - val_loss: 2.6584 - val_acc: 0.0994\n",
      "Epoch 2/24\n",
      "10/10 [==============================] - 12s 1s/step - loss: 3.8663 - acc: 0.1000 - val_loss: 2.6370 - val_acc: 0.1065\n",
      "Epoch 3/24\n",
      "10/10 [==============================] - 12s 1s/step - loss: 2.9943 - acc: 0.0000e+00 - val_loss: 2.6528 - val_acc: 0.0971\n",
      "Epoch 4/24\n",
      "10/10 [==============================] - 12s 1s/step - loss: 3.2043 - acc: 0.2000 - val_loss: 2.6788 - val_acc: 0.0934\n",
      "Epoch 5/24\n",
      "10/10 [==============================] - 12s 1s/step - loss: 3.0577 - acc: 0.1000 - val_loss: 2.5451 - val_acc: 0.0916\n",
      "Epoch 6/24\n",
      "10/10 [==============================] - 12s 1s/step - loss: 2.3366 - acc: 0.2000 - val_loss: 2.4874 - val_acc: 0.0976\n",
      "Epoch 7/24\n",
      "10/10 [==============================] - 13s 1s/step - loss: 2.7759 - acc: 0.1000 - val_loss: 2.5259 - val_acc: 0.0973\n",
      "Epoch 8/24\n",
      "10/10 [==============================] - 13s 1s/step - loss: 1.9256 - acc: 0.3000 - val_loss: 2.5133 - val_acc: 0.0997\n",
      "Epoch 9/24\n",
      "10/10 [==============================] - 13s 1s/step - loss: 2.9012 - acc: 0.1000 - val_loss: 2.4961 - val_acc: 0.1026\n",
      "Epoch 10/24\n",
      "10/10 [==============================] - 13s 1s/step - loss: 2.2168 - acc: 0.2000 - val_loss: 2.5007 - val_acc: 0.1046\n",
      "Epoch 11/24\n",
      "10/10 [==============================] - 13s 1s/step - loss: 2.2729 - acc: 0.1000 - val_loss: 2.5172 - val_acc: 0.1060\n",
      "Epoch 12/24\n",
      "10/10 [==============================] - 19s 2s/step - loss: 2.3176 - acc: 0.3000 - val_loss: 2.5037 - val_acc: 0.1058\n",
      "Epoch 13/24\n",
      "10/10 [==============================] - 14s 1s/step - loss: 2.3027 - acc: 0.3000 - val_loss: 2.4816 - val_acc: 0.1088\n",
      "Epoch 14/24\n",
      "10/10 [==============================] - 14s 1s/step - loss: 2.2849 - acc: 0.3000 - val_loss: 2.4710 - val_acc: 0.1150\n",
      "Epoch 15/24\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.6857 - acc: 0.4000 - val_loss: 2.4803 - val_acc: 0.1113\n",
      "Epoch 16/24\n",
      "10/10 [==============================] - 13s 1s/step - loss: 1.8379 - acc: 0.3000 - val_loss: 2.4954 - val_acc: 0.1137\n",
      "Epoch 17/24\n",
      "10/10 [==============================] - 13s 1s/step - loss: 1.9878 - acc: 0.1000 - val_loss: 2.4829 - val_acc: 0.1130\n",
      "Epoch 18/24\n",
      "10/10 [==============================] - 13s 1s/step - loss: 1.6907 - acc: 0.4000 - val_loss: 2.4732 - val_acc: 0.1126\n",
      "Epoch 19/24\n",
      "10/10 [==============================] - 14s 1s/step - loss: 2.0218 - acc: 0.2000 - val_loss: 2.4793 - val_acc: 0.1159\n",
      "Epoch 20/24\n",
      "10/10 [==============================] - 13s 1s/step - loss: 1.8737 - acc: 0.4000 - val_loss: 2.4879 - val_acc: 0.1106\n",
      "Epoch 21/24\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.6801 - acc: 0.5000 - val_loss: 2.5017 - val_acc: 0.1089\n",
      "Epoch 22/24\n",
      "10/10 [==============================] - 13s 1s/step - loss: 1.8039 - acc: 0.4000 - val_loss: 2.5055 - val_acc: 0.1100\n",
      "Epoch 23/24\n",
      "10/10 [==============================] - 15s 1s/step - loss: 1.6477 - acc: 0.4000 - val_loss: 2.5312 - val_acc: 0.1057\n",
      "Epoch 24/24\n",
      "10/10 [==============================] - 13s 1s/step - loss: 1.8121 - acc: 0.3000 - val_loss: 2.5679 - val_acc: 0.1074\n"
     ]
    }
   ],
   "source": [
    "# print(x_train.shape[1:])\n",
    "\n",
    "cnn_n = base_model()\n",
    "cnn_n.layers[0].tranable = False\n",
    "cnn_n.summary()\n",
    "cnn = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.567911559677124\n",
      "Test accuracy: 0.1074\n"
     ]
    }
   ],
   "source": [
    "score = cnn_n.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_n.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plots for training and testing process: loss and accuracy\n",
    "\n",
    "# plt.figure(0)\n",
    "# plt.plot(cnn.history['acc'],'r')\n",
    "# plt.plot(cnn.history['val_acc'],'g')\n",
    "# plt.xticks(np.arange(0, epochs, 2.0))\n",
    "# plt.rcParams['figure.figsize'] = (8, 6)\n",
    "# plt.xlabel(\"Num of Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
    "# plt.legend(['train','validation'])\n",
    "\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.plot(cnn.history['loss'],'r')\n",
    "# plt.plot(cnn.history['val_loss'],'g')\n",
    "# plt.xticks(np.arange(0, epochs, 2.0))\n",
    "# plt.rcParams['figure.figsize'] = (8, 6)\n",
    "# plt.xlabel(\"Num of Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.title(\"Training Loss vs Validation Loss\")\n",
    "# plt.legend(['train','validation'])\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
