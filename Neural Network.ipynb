{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from skimage.filters import gabor_kernel\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "if K.backend()=='tensorflow':\n",
    "    K.set_image_dim_ordering(\"tf\")\n",
    "from skimage.color import rgb2gray\n",
    "from scipy import ndimage as ndi\n",
    " \n",
    "# Import Tensorflow with multiprocessing\n",
    "import tensorflow as tf\n",
    "import multiprocessing as mp\n",
    " \n",
    "# Loading the CIFAR-10 datasets\n",
    "from keras.datasets import cifar10\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# 32 examples in a mini-batch, smaller batch size means more updates in one epoch\n",
    "num_classes = 10\n",
    "epochs = 24\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(data, dtype='float32'):\n",
    "    # luma coding weighted average in video systems\n",
    "    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\n",
    "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dimension(data):\n",
    "    data = np.array([data])\n",
    "    #re arange the dimension\n",
    "    print(data.shape)\n",
    "    data = np.einsum('hijk->ijkh', data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 32, 32)\n",
      "(1, 100, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "train_selected_amount = 50000\n",
    "test_selected_amount = 10000\n",
    "num_classes = 10\n",
    "\n",
    "init_y_train = y_train[:train_selected_amount]\n",
    "init_y_test = y_test[:test_selected_amount]\n",
    "\n",
    "x_train = add_dimension(grayscale(x_train[:train_selected_amount]))\n",
    "x_test = add_dimension(grayscale(x_test[:test_selected_amount]))\n",
    "y_train = np_utils.to_categorical(init_y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(init_y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train  /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_gabor(shape, dtype=None):\n",
    "#    orientation_spread = np.linspace(0, 8, 8) / 4. * np.pi\n",
    "    pi = np.pi\n",
    "    orientation_spread = np.array([0, pi/4, pi/2, pi*3/4, pi, pi*5/4, pi*3/2, 2*pi])\n",
    "    scales = np.linspace(2, 3, 6)\n",
    "    real_kernels = []\n",
    "#     size, sigma, theta, lambda, gamma aspect ratio\n",
    "    for orientation in orientation_spread:\n",
    "        for scale in scales:\n",
    "            real_kernel = cv2.getGaborKernel((5, 5), 1, orientation, scale, 1, 0)\n",
    "#             real_kernel = np.delete(np.delete(real_kernel, -1, 0), -1, 1)\n",
    "            real_kernels.append(real_kernel)\n",
    "    real_kernels = np.array([real_kernels])\n",
    "    real_kernels = np.einsum('hijk->jkhi', real_kernels)\n",
    "    print(real_kernels.shape)\n",
    "\n",
    "    real_kernels = K.variable(real_kernels)\n",
    "#     print(real_kernels.shape)\n",
    "    random = K.random_normal(shape, dtype=dtype)\n",
    "#     print('here')\n",
    "#     print(random)\n",
    "#     print(random.shape)\n",
    "    return real_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model(shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(48, (3, 3), padding='same',kernel_initializer=custom_gabor, data_format='channels_last', input_shape=shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    # sgd = SGD(lr = 0.1, decay = 1e-6, momentum=0.9, nesterov=True)\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "    # Train model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 1, 48)\n",
      "here\n",
      "Tensor(\"conv2d_44/random_normal:0\", shape=(3, 3, 1, 48), dtype=float32)\n",
      "(3, 3, 1, 48)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_44 (Conv2D)           (None, 32, 32, 48)        480       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 32, 32, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 30, 30, 32)        13856     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,255,050\n",
      "Trainable params: 1,255,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/24\n",
      "10/10 [==============================] - 1s 59ms/step - loss: 3.1719 - acc: 0.0000e+00 - val_loss: 2.2957 - val_acc: 0.1000\n",
      "Epoch 2/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.6872 - acc: 0.0000e+00 - val_loss: 2.3281 - val_acc: 0.0000e+00\n",
      "Epoch 3/24\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 2.6373 - acc: 0.0000e+00 - val_loss: 2.3816 - val_acc: 0.0000e+00\n",
      "Epoch 4/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.1787 - acc: 0.2000 - val_loss: 2.4187 - val_acc: 0.0000e+00\n",
      "Epoch 5/24\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 2.1113 - acc: 0.2000 - val_loss: 2.3895 - val_acc: 0.0000e+00\n",
      "Epoch 6/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.2542 - acc: 0.1000 - val_loss: 2.3865 - val_acc: 0.0000e+00\n",
      "Epoch 7/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.9124 - acc: 0.3000 - val_loss: 2.3932 - val_acc: 0.0000e+00\n",
      "Epoch 8/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.0283 - acc: 0.3000 - val_loss: 2.3717 - val_acc: 0.0000e+00\n",
      "Epoch 9/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.9991 - acc: 0.1000 - val_loss: 2.4109 - val_acc: 0.0000e+00\n",
      "Epoch 10/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.8766 - acc: 0.3000 - val_loss: 2.4369 - val_acc: 0.0000e+00\n",
      "Epoch 11/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.9625 - acc: 0.3000 - val_loss: 2.4085 - val_acc: 0.0000e+00\n",
      "Epoch 12/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.6577 - acc: 0.4000 - val_loss: 2.4042 - val_acc: 0.0000e+00\n",
      "Epoch 13/24\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.9481 - acc: 0.4000 - val_loss: 2.3958 - val_acc: 0.0000e+00\n",
      "Epoch 14/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.2149 - acc: 0.1000 - val_loss: 2.3945 - val_acc: 0.0000e+00\n",
      "Epoch 15/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.9858 - acc: 0.2000 - val_loss: 2.4003 - val_acc: 0.0000e+00\n",
      "Epoch 16/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.0421 - acc: 0.1000 - val_loss: 2.4023 - val_acc: 0.0000e+00\n",
      "Epoch 17/24\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.9129 - acc: 0.2000 - val_loss: 2.3906 - val_acc: 0.0000e+00\n",
      "Epoch 18/24\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.8491 - acc: 0.3000 - val_loss: 2.3821 - val_acc: 0.0000e+00\n",
      "Epoch 19/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.6352 - acc: 0.3000 - val_loss: 2.3950 - val_acc: 0.0000e+00\n",
      "Epoch 20/24\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.9088 - acc: 0.3000 - val_loss: 2.3892 - val_acc: 0.0000e+00\n",
      "Epoch 21/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.7579 - acc: 0.3000 - val_loss: 2.3816 - val_acc: 0.0000e+00\n",
      "Epoch 22/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.1468 - acc: 0.2000 - val_loss: 2.3681 - val_acc: 0.0000e+00\n",
      "Epoch 23/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.8441 - acc: 0.3000 - val_loss: 2.3592 - val_acc: 0.0000e+00\n",
      "Epoch 24/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.8339 - acc: 0.4000 - val_loss: 2.3520 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# cnn_n = base_model(x_train.shape[1:])\n",
    "# cnn_n.summary()\n",
    "\n",
    "# cnn = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.3519577980041504\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# score = cnn_n.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/golfo/anaconda/envs/tensorflow36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  0\n",
      "(3, 3, 1, 48)\n",
      "here\n",
      "Tensor(\"conv2d_128/random_normal:0\", shape=(3, 3, 1, 48), dtype=float32)\n",
      "(3, 3, 1, 48)\n",
      "Train on 84 samples, validate on 16 samples\n",
      "Epoch 1/24\n",
      "84/84 [==============================] - 2s 19ms/step - loss: 3.5721 - acc: 0.0952 - val_loss: 2.2651 - val_acc: 0.1875\n",
      "Epoch 2/24\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 2.7517 - acc: 0.1310 - val_loss: 2.2565 - val_acc: 0.1250\n",
      "Epoch 3/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.5371 - acc: 0.2024 - val_loss: 2.2700 - val_acc: 0.0625\n",
      "Epoch 4/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.5705 - acc: 0.1190 - val_loss: 2.2512 - val_acc: 0.1250\n",
      "Epoch 5/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.5603 - acc: 0.1071 - val_loss: 2.2660 - val_acc: 0.1250\n",
      "Epoch 6/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.4210 - acc: 0.1310 - val_loss: 2.2702 - val_acc: 0.1875\n",
      "Epoch 7/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.2542 - acc: 0.2024 - val_loss: 2.2661 - val_acc: 0.1250\n",
      "Epoch 8/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.1935 - acc: 0.2262 - val_loss: 2.2596 - val_acc: 0.1875\n",
      "Epoch 9/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.2825 - acc: 0.1429 - val_loss: 2.2481 - val_acc: 0.1250\n",
      "Epoch 10/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.3197 - acc: 0.1667 - val_loss: 2.2439 - val_acc: 0.1250\n",
      "Epoch 11/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.3441 - acc: 0.1310 - val_loss: 2.2458 - val_acc: 0.2500\n",
      "Epoch 12/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.2428 - acc: 0.1548 - val_loss: 2.2493 - val_acc: 0.1250\n",
      "Epoch 13/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.3243 - acc: 0.1429 - val_loss: 2.2537 - val_acc: 0.1250\n",
      "Epoch 14/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.2242 - acc: 0.1905 - val_loss: 2.2592 - val_acc: 0.1250\n",
      "Epoch 15/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.2168 - acc: 0.2143 - val_loss: 2.2597 - val_acc: 0.1250\n",
      "Epoch 16/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.2366 - acc: 0.1310 - val_loss: 2.2583 - val_acc: 0.1875\n",
      "Epoch 17/24\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 2.1675 - acc: 0.2143 - val_loss: 2.2625 - val_acc: 0.1875\n",
      "Epoch 18/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.2190 - acc: 0.1429 - val_loss: 2.2646 - val_acc: 0.1250\n",
      "Epoch 19/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.2474 - acc: 0.1190 - val_loss: 2.2611 - val_acc: 0.1250\n",
      "Epoch 20/24\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 2.1734 - acc: 0.1786 - val_loss: 2.2518 - val_acc: 0.1250\n",
      "Epoch 21/24\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 2.1665 - acc: 0.1786 - val_loss: 2.2434 - val_acc: 0.1250\n",
      "Epoch 22/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.1794 - acc: 0.1667 - val_loss: 2.2481 - val_acc: 0.1875\n",
      "Epoch 23/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.1469 - acc: 0.1905 - val_loss: 2.2570 - val_acc: 0.1875\n",
      "Epoch 24/24\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 2.0870 - acc: 0.2262 - val_loss: 2.2589 - val_acc: 0.1875\n",
      "fold  1\n",
      "(3, 3, 1, 48)\n",
      "here\n",
      "Tensor(\"conv2d_132/random_normal:0\", shape=(3, 3, 1, 48), dtype=float32)\n",
      "(3, 3, 1, 48)\n",
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/24\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 3.5330 - acc: 0.1222 - val_loss: 2.1935 - val_acc: 0.3000\n",
      "Epoch 2/24\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8647 - acc: 0.1111 - val_loss: 2.1641 - val_acc: 0.1000\n",
      "Epoch 3/24\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7066 - acc: 0.1222 - val_loss: 2.1635 - val_acc: 0.3000\n",
      "Epoch 4/24\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7057 - acc: 0.1222 - val_loss: 2.1184 - val_acc: 0.4000\n",
      "Epoch 5/24\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4546 - acc: 0.1667 - val_loss: 2.1087 - val_acc: 0.3000\n",
      "Epoch 6/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.3860 - acc: 0.1000 - val_loss: 2.1170 - val_acc: 0.4000\n",
      "Epoch 7/24\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4467 - acc: 0.1333 - val_loss: 2.1220 - val_acc: 0.3000\n",
      "Epoch 8/24\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3147 - acc: 0.1667 - val_loss: 2.1418 - val_acc: 0.2000\n",
      "Epoch 9/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.3609 - acc: 0.1667 - val_loss: 2.1331 - val_acc: 0.2000\n",
      "Epoch 10/24\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4784 - acc: 0.1333 - val_loss: 2.1266 - val_acc: 0.1000\n",
      "Epoch 11/24\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3182 - acc: 0.1444 - val_loss: 2.1300 - val_acc: 0.2000\n",
      "Epoch 12/24\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3760 - acc: 0.1222 - val_loss: 2.1326 - val_acc: 0.1000\n",
      "Epoch 13/24\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2724 - acc: 0.1444 - val_loss: 2.1355 - val_acc: 0.2000\n",
      "Epoch 14/24\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4126 - acc: 0.1444 - val_loss: 2.1374 - val_acc: 0.1000\n",
      "Epoch 15/24\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3162 - acc: 0.1111 - val_loss: 2.1393 - val_acc: 0.2000\n",
      "Epoch 16/24\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2084 - acc: 0.1556 - val_loss: 2.1369 - val_acc: 0.3000\n",
      "Epoch 17/24\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2803 - acc: 0.1667 - val_loss: 2.1226 - val_acc: 0.3000\n",
      "Epoch 18/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2529 - acc: 0.2000 - val_loss: 2.1222 - val_acc: 0.3000\n",
      "Epoch 19/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2704 - acc: 0.1444 - val_loss: 2.1282 - val_acc: 0.2000\n",
      "Epoch 20/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1630 - acc: 0.1778 - val_loss: 2.1311 - val_acc: 0.1000\n",
      "Epoch 21/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1909 - acc: 0.2444 - val_loss: 2.1367 - val_acc: 0.3000\n",
      "Epoch 22/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2197 - acc: 0.2222 - val_loss: 2.1349 - val_acc: 0.4000\n",
      "Epoch 23/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2146 - acc: 0.2000 - val_loss: 2.1211 - val_acc: 0.4000\n",
      "Epoch 24/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1421 - acc: 0.2444 - val_loss: 2.1250 - val_acc: 0.2000\n",
      "fold  2\n",
      "(3, 3, 1, 48)\n",
      "here\n",
      "Tensor(\"conv2d_136/random_normal:0\", shape=(3, 3, 1, 48), dtype=float32)\n",
      "(3, 3, 1, 48)\n",
      "Train on 89 samples, validate on 11 samples\n",
      "Epoch 1/24\n",
      "89/89 [==============================] - 2s 20ms/step - loss: 3.1453 - acc: 0.1124 - val_loss: 2.2118 - val_acc: 0.1818\n",
      "Epoch 2/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.7219 - acc: 0.1011 - val_loss: 2.2665 - val_acc: 0.1818\n",
      "Epoch 3/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.5482 - acc: 0.1124 - val_loss: 2.2299 - val_acc: 0.1818\n",
      "Epoch 4/24\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.4725 - acc: 0.1573 - val_loss: 2.1872 - val_acc: 0.1818\n",
      "Epoch 5/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.4682 - acc: 0.1685 - val_loss: 2.1621 - val_acc: 0.1818\n",
      "Epoch 6/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.2923 - acc: 0.2247 - val_loss: 2.1627 - val_acc: 0.1818\n",
      "Epoch 7/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.4106 - acc: 0.1124 - val_loss: 2.1744 - val_acc: 0.1818\n",
      "Epoch 8/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.3361 - acc: 0.1236 - val_loss: 2.1813 - val_acc: 0.1818\n",
      "Epoch 9/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2885 - acc: 0.1798 - val_loss: 2.1784 - val_acc: 0.1818\n",
      "Epoch 10/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.2574 - acc: 0.2135 - val_loss: 2.1844 - val_acc: 0.1818\n",
      "Epoch 11/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.3336 - acc: 0.1348 - val_loss: 2.1859 - val_acc: 0.1818\n",
      "Epoch 12/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.3125 - acc: 0.1685 - val_loss: 2.1856 - val_acc: 0.1818\n",
      "Epoch 13/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.3408 - acc: 0.1011 - val_loss: 2.1891 - val_acc: 0.2727\n",
      "Epoch 14/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.2489 - acc: 0.1798 - val_loss: 2.1867 - val_acc: 0.2727\n",
      "Epoch 15/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.3077 - acc: 0.1011 - val_loss: 2.1837 - val_acc: 0.2727\n",
      "Epoch 16/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.2724 - acc: 0.1573 - val_loss: 2.1878 - val_acc: 0.2727\n",
      "Epoch 17/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.2281 - acc: 0.1910 - val_loss: 2.1768 - val_acc: 0.2727\n",
      "Epoch 18/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.2015 - acc: 0.1910 - val_loss: 2.1896 - val_acc: 0.2727\n",
      "Epoch 19/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.3110 - acc: 0.1910 - val_loss: 2.1894 - val_acc: 0.2727\n",
      "Epoch 20/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.2168 - acc: 0.1685 - val_loss: 2.1969 - val_acc: 0.2727\n",
      "Epoch 21/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.1991 - acc: 0.1685 - val_loss: 2.2039 - val_acc: 0.2727\n",
      "Epoch 22/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.2853 - acc: 0.1573 - val_loss: 2.2027 - val_acc: 0.2727\n",
      "Epoch 23/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.2777 - acc: 0.1685 - val_loss: 2.1940 - val_acc: 0.2727\n",
      "Epoch 24/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.1720 - acc: 0.2247 - val_loss: 2.1885 - val_acc: 0.1818\n",
      "fold  3\n",
      "(3, 3, 1, 48)\n",
      "here\n",
      "Tensor(\"conv2d_140/random_normal:0\", shape=(3, 3, 1, 48), dtype=float32)\n",
      "(3, 3, 1, 48)\n",
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/24\n",
      "90/90 [==============================] - 2s 22ms/step - loss: 3.0477 - acc: 0.1667 - val_loss: 2.3075 - val_acc: 0.0000e+00\n",
      "Epoch 2/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.6883 - acc: 0.1333 - val_loss: 2.3555 - val_acc: 0.2000\n",
      "Epoch 3/24\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 2.8019 - acc: 0.0667 - val_loss: 2.3259 - val_acc: 0.2000\n",
      "Epoch 4/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.5622 - acc: 0.1111 - val_loss: 2.3180 - val_acc: 0.3000\n",
      "Epoch 5/24\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 2.5375 - acc: 0.0889 - val_loss: 2.3155 - val_acc: 0.1000\n",
      "Epoch 6/24\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 2.3512 - acc: 0.1444 - val_loss: 2.3185 - val_acc: 0.0000e+00\n",
      "Epoch 7/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2861 - acc: 0.1444 - val_loss: 2.3276 - val_acc: 0.0000e+00\n",
      "Epoch 8/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.3414 - acc: 0.1444 - val_loss: 2.3290 - val_acc: 0.0000e+00\n",
      "Epoch 9/24\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 2.3566 - acc: 0.1667 - val_loss: 2.3219 - val_acc: 0.1000\n",
      "Epoch 10/24\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 2.2525 - acc: 0.1556 - val_loss: 2.3148 - val_acc: 0.0000e+00\n",
      "Epoch 11/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2626 - acc: 0.1556 - val_loss: 2.3141 - val_acc: 0.2000\n",
      "Epoch 12/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2357 - acc: 0.1667 - val_loss: 2.3296 - val_acc: 0.2000\n",
      "Epoch 13/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2035 - acc: 0.1889 - val_loss: 2.3362 - val_acc: 0.2000\n",
      "Epoch 14/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2661 - acc: 0.1889 - val_loss: 2.3381 - val_acc: 0.0000e+00\n",
      "Epoch 15/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1757 - acc: 0.1889 - val_loss: 2.3258 - val_acc: 0.0000e+00\n",
      "Epoch 16/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1692 - acc: 0.1778 - val_loss: 2.3368 - val_acc: 0.0000e+00\n",
      "Epoch 17/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1631 - acc: 0.2333 - val_loss: 2.3351 - val_acc: 0.0000e+00\n",
      "Epoch 18/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2212 - acc: 0.1778 - val_loss: 2.3265 - val_acc: 0.0000e+00\n",
      "Epoch 19/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2049 - acc: 0.2000 - val_loss: 2.3420 - val_acc: 0.0000e+00\n",
      "Epoch 20/24\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1185 - acc: 0.2333 - val_loss: 2.3460 - val_acc: 0.0000e+00\n",
      "Epoch 21/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.0980 - acc: 0.2222 - val_loss: 2.3545 - val_acc: 0.0000e+00\n",
      "Epoch 22/24\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 2.1221 - acc: 0.1778 - val_loss: 2.3661 - val_acc: 0.0000e+00\n",
      "Epoch 23/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.9920 - acc: 0.2889 - val_loss: 2.3654 - val_acc: 0.0000e+00\n",
      "Epoch 24/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1292 - acc: 0.1778 - val_loss: 2.3761 - val_acc: 0.0000e+00\n",
      "fold  4\n",
      "(3, 3, 1, 48)\n",
      "here\n",
      "Tensor(\"conv2d_144/random_normal:0\", shape=(3, 3, 1, 48), dtype=float32)\n",
      "(3, 3, 1, 48)\n",
      "Train on 89 samples, validate on 11 samples\n",
      "Epoch 1/24\n",
      "89/89 [==============================] - 2s 23ms/step - loss: 2.7135 - acc: 0.0899 - val_loss: 2.2851 - val_acc: 0.0000e+00\n",
      "Epoch 2/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.4102 - acc: 0.1573 - val_loss: 2.2966 - val_acc: 0.0909\n",
      "Epoch 3/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.3588 - acc: 0.1348 - val_loss: 2.3088 - val_acc: 0.0909\n",
      "Epoch 4/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.3622 - acc: 0.1124 - val_loss: 2.3135 - val_acc: 0.1818\n",
      "Epoch 5/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.2468 - acc: 0.1348 - val_loss: 2.3102 - val_acc: 0.0909\n",
      "Epoch 6/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2069 - acc: 0.1573 - val_loss: 2.3057 - val_acc: 0.1818\n",
      "Epoch 7/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2954 - acc: 0.1573 - val_loss: 2.3031 - val_acc: 0.1818\n",
      "Epoch 8/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2294 - acc: 0.1685 - val_loss: 2.3126 - val_acc: 0.0909\n",
      "Epoch 9/24\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 2.2444 - acc: 0.1798 - val_loss: 2.3085 - val_acc: 0.0909\n",
      "Epoch 10/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2935 - acc: 0.1124 - val_loss: 2.3075 - val_acc: 0.1818\n",
      "Epoch 11/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.1725 - acc: 0.2247 - val_loss: 2.3039 - val_acc: 0.0909\n",
      "Epoch 12/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.1889 - acc: 0.2472 - val_loss: 2.3057 - val_acc: 0.1818\n",
      "Epoch 13/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.1762 - acc: 0.1798 - val_loss: 2.3004 - val_acc: 0.1818\n",
      "Epoch 14/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.1199 - acc: 0.1685 - val_loss: 2.2970 - val_acc: 0.2727\n",
      "Epoch 15/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2046 - acc: 0.2135 - val_loss: 2.2967 - val_acc: 0.2727\n",
      "Epoch 16/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2207 - acc: 0.2247 - val_loss: 2.3012 - val_acc: 0.1818\n",
      "Epoch 17/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2116 - acc: 0.2247 - val_loss: 2.2906 - val_acc: 0.1818\n",
      "Epoch 18/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.1341 - acc: 0.2247 - val_loss: 2.2873 - val_acc: 0.1818\n",
      "Epoch 19/24\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.1635 - acc: 0.1910 - val_loss: 2.2993 - val_acc: 0.1818\n",
      "Epoch 20/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.1520 - acc: 0.2247 - val_loss: 2.2948 - val_acc: 0.0909\n",
      "Epoch 21/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.0787 - acc: 0.2022 - val_loss: 2.3068 - val_acc: 0.0909\n",
      "Epoch 22/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.0748 - acc: 0.2360 - val_loss: 2.3025 - val_acc: 0.0909\n",
      "Epoch 23/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.0485 - acc: 0.2921 - val_loss: 2.2897 - val_acc: 0.1818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.0740 - acc: 0.2360 - val_loss: 2.2903 - val_acc: 0.1818\n",
      "fold  5\n",
      "(3, 3, 1, 48)\n",
      "here\n",
      "Tensor(\"conv2d_148/random_normal:0\", shape=(3, 3, 1, 48), dtype=float32)\n",
      "(3, 3, 1, 48)\n",
      "Train on 89 samples, validate on 11 samples\n",
      "Epoch 1/24\n",
      "89/89 [==============================] - 2s 21ms/step - loss: 2.9279 - acc: 0.1011 - val_loss: 2.3471 - val_acc: 0.0000e+00\n",
      "Epoch 2/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.5193 - acc: 0.1798 - val_loss: 2.3128 - val_acc: 0.1818\n",
      "Epoch 3/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.5933 - acc: 0.1236 - val_loss: 2.3051 - val_acc: 0.0909\n",
      "Epoch 4/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.4858 - acc: 0.1348 - val_loss: 2.3031 - val_acc: 0.0909\n",
      "Epoch 5/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.4824 - acc: 0.1236 - val_loss: 2.3089 - val_acc: 0.0909\n",
      "Epoch 6/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.4987 - acc: 0.1348 - val_loss: 2.3194 - val_acc: 0.0909\n",
      "Epoch 7/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.4119 - acc: 0.0899 - val_loss: 2.3057 - val_acc: 0.1818\n",
      "Epoch 8/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2363 - acc: 0.2247 - val_loss: 2.3125 - val_acc: 0.0909\n",
      "Epoch 9/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.3328 - acc: 0.1236 - val_loss: 2.3128 - val_acc: 0.1818\n",
      "Epoch 10/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2652 - acc: 0.1124 - val_loss: 2.3085 - val_acc: 0.1818\n",
      "Epoch 11/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.3298 - acc: 0.1236 - val_loss: 2.3069 - val_acc: 0.0909\n",
      "Epoch 12/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2358 - acc: 0.1685 - val_loss: 2.3083 - val_acc: 0.0909\n",
      "Epoch 13/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2272 - acc: 0.1348 - val_loss: 2.3080 - val_acc: 0.1818\n",
      "Epoch 14/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.1875 - acc: 0.2247 - val_loss: 2.3091 - val_acc: 0.1818\n",
      "Epoch 15/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.1379 - acc: 0.2135 - val_loss: 2.3034 - val_acc: 0.0909\n",
      "Epoch 16/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.2282 - acc: 0.1573 - val_loss: 2.3028 - val_acc: 0.0909\n",
      "Epoch 17/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.2064 - acc: 0.1910 - val_loss: 2.2943 - val_acc: 0.0909\n",
      "Epoch 18/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.1617 - acc: 0.2360 - val_loss: 2.2992 - val_acc: 0.2727\n",
      "Epoch 19/24\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.1754 - acc: 0.1685 - val_loss: 2.2952 - val_acc: 0.1818\n",
      "Epoch 20/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.1494 - acc: 0.1461 - val_loss: 2.2884 - val_acc: 0.1818\n",
      "Epoch 21/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2091 - acc: 0.2135 - val_loss: 2.2899 - val_acc: 0.3636\n",
      "Epoch 22/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.1736 - acc: 0.2360 - val_loss: 2.3052 - val_acc: 0.0909\n",
      "Epoch 23/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.0723 - acc: 0.3258 - val_loss: 2.3057 - val_acc: 0.0909\n",
      "Epoch 24/24\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2010 - acc: 0.1685 - val_loss: 2.2984 - val_acc: 0.0909\n",
      "fold  6\n",
      "(3, 3, 1, 48)\n",
      "here\n",
      "Tensor(\"conv2d_152/random_normal:0\", shape=(3, 3, 1, 48), dtype=float32)\n",
      "(3, 3, 1, 48)\n",
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/24\n",
      "90/90 [==============================] - 2s 25ms/step - loss: 3.1190 - acc: 0.1222 - val_loss: 2.3311 - val_acc: 0.2000\n",
      "Epoch 2/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.8223 - acc: 0.1556 - val_loss: 2.3073 - val_acc: 0.3000\n",
      "Epoch 3/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.5796 - acc: 0.1000 - val_loss: 2.3078 - val_acc: 0.1000\n",
      "Epoch 4/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.4384 - acc: 0.1556 - val_loss: 2.2826 - val_acc: 0.1000\n",
      "Epoch 5/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.5901 - acc: 0.1444 - val_loss: 2.2672 - val_acc: 0.2000\n",
      "Epoch 6/24\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 2.4142 - acc: 0.1556 - val_loss: 2.2668 - val_acc: 0.1000\n",
      "Epoch 7/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2574 - acc: 0.2111 - val_loss: 2.2706 - val_acc: 0.1000\n",
      "Epoch 8/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2730 - acc: 0.1556 - val_loss: 2.2730 - val_acc: 0.2000\n",
      "Epoch 9/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.3243 - acc: 0.1444 - val_loss: 2.2680 - val_acc: 0.1000\n",
      "Epoch 10/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2509 - acc: 0.1778 - val_loss: 2.2593 - val_acc: 0.1000\n",
      "Epoch 11/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1744 - acc: 0.2667 - val_loss: 2.2577 - val_acc: 0.1000\n",
      "Epoch 12/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2193 - acc: 0.1667 - val_loss: 2.2616 - val_acc: 0.2000\n",
      "Epoch 13/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1820 - acc: 0.2111 - val_loss: 2.2629 - val_acc: 0.2000\n",
      "Epoch 14/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2659 - acc: 0.1556 - val_loss: 2.2563 - val_acc: 0.2000\n",
      "Epoch 15/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1683 - acc: 0.2889 - val_loss: 2.2636 - val_acc: 0.2000\n",
      "Epoch 16/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2159 - acc: 0.1889 - val_loss: 2.2672 - val_acc: 0.2000\n",
      "Epoch 17/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1868 - acc: 0.2222 - val_loss: 2.2578 - val_acc: 0.2000\n",
      "Epoch 18/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1867 - acc: 0.2222 - val_loss: 2.2560 - val_acc: 0.2000\n",
      "Epoch 19/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1586 - acc: 0.2667 - val_loss: 2.2545 - val_acc: 0.2000\n",
      "Epoch 20/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1489 - acc: 0.2111 - val_loss: 2.2377 - val_acc: 0.3000\n",
      "Epoch 21/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.0575 - acc: 0.2556 - val_loss: 2.2178 - val_acc: 0.3000\n",
      "Epoch 22/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1229 - acc: 0.2333 - val_loss: 2.2346 - val_acc: 0.3000\n",
      "Epoch 23/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.0735 - acc: 0.2222 - val_loss: 2.2352 - val_acc: 0.2000\n",
      "Epoch 24/24\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1624 - acc: 0.1889 - val_loss: 2.2283 - val_acc: 0.3000\n",
      "fold  7\n",
      "(3, 3, 1, 48)\n",
      "here\n",
      "Tensor(\"conv2d_156/random_normal:0\", shape=(3, 3, 1, 48), dtype=float32)\n",
      "(3, 3, 1, 48)\n",
      "Train on 94 samples, validate on 6 samples\n",
      "Epoch 1/24\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 3.5593 - acc: 0.1064 - val_loss: 2.1769 - val_acc: 0.0000e+00\n",
      "Epoch 2/24\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 2.7280 - acc: 0.1596 - val_loss: 2.1419 - val_acc: 0.0000e+00\n",
      "Epoch 3/24\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 2.6848 - acc: 0.1596 - val_loss: 2.1805 - val_acc: 0.0000e+00\n",
      "Epoch 4/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.5228 - acc: 0.1383 - val_loss: 2.1992 - val_acc: 0.0000e+00\n",
      "Epoch 5/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.4262 - acc: 0.2021 - val_loss: 2.2183 - val_acc: 0.3333\n",
      "Epoch 6/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.5056 - acc: 0.0851 - val_loss: 2.2069 - val_acc: 0.0000e+00\n",
      "Epoch 7/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.4610 - acc: 0.1489 - val_loss: 2.1802 - val_acc: 0.1667\n",
      "Epoch 8/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.3325 - acc: 0.1809 - val_loss: 2.1673 - val_acc: 0.1667\n",
      "Epoch 9/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2903 - acc: 0.1915 - val_loss: 2.1882 - val_acc: 0.0000e+00\n",
      "Epoch 10/24\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 2.3476 - acc: 0.1064 - val_loss: 2.1888 - val_acc: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 2.1986 - acc: 0.2766 - val_loss: 2.1707 - val_acc: 0.1667\n",
      "Epoch 12/24\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 2.2297 - acc: 0.2021 - val_loss: 2.1861 - val_acc: 0.1667\n",
      "Epoch 13/24\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 2.2822 - acc: 0.1596 - val_loss: 2.1673 - val_acc: 0.3333\n",
      "Epoch 14/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2804 - acc: 0.1809 - val_loss: 2.1584 - val_acc: 0.3333\n",
      "Epoch 15/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2488 - acc: 0.2234 - val_loss: 2.1567 - val_acc: 0.3333\n",
      "Epoch 16/24\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 2.3007 - acc: 0.1489 - val_loss: 2.1555 - val_acc: 0.3333\n",
      "Epoch 17/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2026 - acc: 0.1596 - val_loss: 2.1529 - val_acc: 0.1667\n",
      "Epoch 18/24\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 2.1980 - acc: 0.2021 - val_loss: 2.1437 - val_acc: 0.1667\n",
      "Epoch 19/24\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 2.2800 - acc: 0.1915 - val_loss: 2.1577 - val_acc: 0.1667\n",
      "Epoch 20/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.1069 - acc: 0.2979 - val_loss: 2.1544 - val_acc: 0.1667\n",
      "Epoch 21/24\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 2.2190 - acc: 0.1702 - val_loss: 2.1657 - val_acc: 0.1667\n",
      "Epoch 22/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2274 - acc: 0.1809 - val_loss: 2.1760 - val_acc: 0.1667\n",
      "Epoch 23/24\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 2.1728 - acc: 0.1383 - val_loss: 2.1671 - val_acc: 0.1667\n",
      "Epoch 24/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.1827 - acc: 0.2447 - val_loss: 2.1653 - val_acc: 0.1667\n",
      "fold  8\n",
      "(3, 3, 1, 48)\n",
      "here\n",
      "Tensor(\"conv2d_160/random_normal:0\", shape=(3, 3, 1, 48), dtype=float32)\n",
      "(3, 3, 1, 48)\n",
      "Train on 94 samples, validate on 6 samples\n",
      "Epoch 1/24\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 3.6374 - acc: 0.0638 - val_loss: 2.1994 - val_acc: 0.0000e+00\n",
      "Epoch 2/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.6967 - acc: 0.1702 - val_loss: 2.2734 - val_acc: 0.0000e+00\n",
      "Epoch 3/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.5888 - acc: 0.1915 - val_loss: 2.2464 - val_acc: 0.1667\n",
      "Epoch 4/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.4763 - acc: 0.2021 - val_loss: 2.2358 - val_acc: 0.1667\n",
      "Epoch 5/24\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 2.5595 - acc: 0.0957 - val_loss: 2.2322 - val_acc: 0.0000e+00\n",
      "Epoch 6/24\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 2.6559 - acc: 0.0957 - val_loss: 2.2335 - val_acc: 0.0000e+00\n",
      "Epoch 7/24\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 2.3659 - acc: 0.1489 - val_loss: 2.2698 - val_acc: 0.0000e+00\n",
      "Epoch 8/24\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 2.3879 - acc: 0.1064 - val_loss: 2.2128 - val_acc: 0.1667\n",
      "Epoch 9/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.4186 - acc: 0.0745 - val_loss: 2.1954 - val_acc: 0.1667\n",
      "Epoch 10/24\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 2.3559 - acc: 0.1596 - val_loss: 2.2023 - val_acc: 0.1667\n",
      "Epoch 11/24\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 2.3816 - acc: 0.0851 - val_loss: 2.2435 - val_acc: 0.1667\n",
      "Epoch 12/24\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 2.2555 - acc: 0.1383 - val_loss: 2.2091 - val_acc: 0.1667\n",
      "Epoch 13/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.3715 - acc: 0.1489 - val_loss: 2.2111 - val_acc: 0.1667\n",
      "Epoch 14/24\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 2.1502 - acc: 0.2340 - val_loss: 2.2317 - val_acc: 0.1667\n",
      "Epoch 15/24\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 2.2848 - acc: 0.1489 - val_loss: 2.2173 - val_acc: 0.1667\n",
      "Epoch 16/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2222 - acc: 0.1702 - val_loss: 2.1970 - val_acc: 0.0000e+00\n",
      "Epoch 17/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.3756 - acc: 0.1383 - val_loss: 2.2165 - val_acc: 0.0000e+00\n",
      "Epoch 18/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2319 - acc: 0.1915 - val_loss: 2.1985 - val_acc: 0.0000e+00\n",
      "Epoch 19/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.1904 - acc: 0.1915 - val_loss: 2.1950 - val_acc: 0.0000e+00\n",
      "Epoch 20/24\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 2.2227 - acc: 0.2128 - val_loss: 2.2109 - val_acc: 0.0000e+00\n",
      "Epoch 21/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2154 - acc: 0.1809 - val_loss: 2.1868 - val_acc: 0.1667\n",
      "Epoch 22/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2776 - acc: 0.1596 - val_loss: 2.1971 - val_acc: 0.0000e+00\n",
      "Epoch 23/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2789 - acc: 0.1596 - val_loss: 2.2066 - val_acc: 0.0000e+00\n",
      "Epoch 24/24\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2723 - acc: 0.1383 - val_loss: 2.2302 - val_acc: 0.0000e+00\n",
      "fold  9\n",
      "(3, 3, 1, 48)\n",
      "here\n",
      "Tensor(\"conv2d_164/random_normal:0\", shape=(3, 3, 1, 48), dtype=float32)\n",
      "(3, 3, 1, 48)\n",
      "Train on 91 samples, validate on 9 samples\n",
      "Epoch 1/24\n",
      "91/91 [==============================] - 2s 22ms/step - loss: 2.7755 - acc: 0.1099 - val_loss: 2.2815 - val_acc: 0.1111\n",
      "Epoch 2/24\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 2.5563 - acc: 0.1429 - val_loss: 2.2443 - val_acc: 0.1111\n",
      "Epoch 3/24\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 2.4625 - acc: 0.1758 - val_loss: 2.2357 - val_acc: 0.1111\n",
      "Epoch 4/24\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.4385 - acc: 0.1209 - val_loss: 2.2283 - val_acc: 0.1111\n",
      "Epoch 5/24\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 2.3734 - acc: 0.1209 - val_loss: 2.2204 - val_acc: 0.2222\n",
      "Epoch 6/24\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 2.2979 - acc: 0.0879 - val_loss: 2.2085 - val_acc: 0.2222\n",
      "Epoch 7/24\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.3241 - acc: 0.1209 - val_loss: 2.2062 - val_acc: 0.2222\n",
      "Epoch 8/24\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.2463 - acc: 0.2308 - val_loss: 2.2023 - val_acc: 0.2222\n",
      "Epoch 9/24\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.2857 - acc: 0.1648 - val_loss: 2.1958 - val_acc: 0.1111\n",
      "Epoch 10/24\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.1995 - acc: 0.2418 - val_loss: 2.1909 - val_acc: 0.1111\n",
      "Epoch 11/24\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 2.2505 - acc: 0.1319 - val_loss: 2.1889 - val_acc: 0.1111\n",
      "Epoch 12/24\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.1944 - acc: 0.1978 - val_loss: 2.1892 - val_acc: 0.2222\n",
      "Epoch 13/24\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.3027 - acc: 0.1538 - val_loss: 2.1961 - val_acc: 0.2222\n",
      "Epoch 14/24\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.2395 - acc: 0.1429 - val_loss: 2.2018 - val_acc: 0.1111\n",
      "Epoch 15/24\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.1937 - acc: 0.2198 - val_loss: 2.2008 - val_acc: 0.1111\n",
      "Epoch 16/24\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.2756 - acc: 0.2857 - val_loss: 2.1945 - val_acc: 0.2222\n",
      "Epoch 17/24\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.1900 - acc: 0.1648 - val_loss: 2.1846 - val_acc: 0.3333\n",
      "Epoch 18/24\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.1423 - acc: 0.2637 - val_loss: 2.1860 - val_acc: 0.3333\n",
      "Epoch 19/24\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.1625 - acc: 0.2088 - val_loss: 2.1930 - val_acc: 0.1111\n",
      "Epoch 20/24\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.1189 - acc: 0.1978 - val_loss: 2.1929 - val_acc: 0.1111\n",
      "Epoch 21/24\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 2.1825 - acc: 0.1758 - val_loss: 2.1818 - val_acc: 0.1111\n",
      "Epoch 22/24\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 2.1341 - acc: 0.1868 - val_loss: 2.1899 - val_acc: 0.1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 2.1163 - acc: 0.2088 - val_loss: 2.1971 - val_acc: 0.1111\n",
      "Epoch 24/24\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 2.0657 - acc: 0.2747 - val_loss: 2.1902 - val_acc: 0.1111\n",
      "average accuracy: 12.60% (+/- 3.41%)\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "scores = []\n",
    "folds = list(StratifiedKFold(n_splits=k, shuffle=True, random_state=1).split(x_train, init_y_train))\n",
    "for j, (train_idx, val_idx) in enumerate(folds):\n",
    "    print('fold ', j)\n",
    "    x_train_cv = x_train[train_idx]\n",
    "    y_train_cv = y_train[train_idx]\n",
    "    x_valid_cv = x_train[val_idx]\n",
    "    y_valid_cv = y_train[val_idx]\n",
    "    model = base_model(x_train_cv.shape[1:])\n",
    "    model.fit(x_train_cv, y_train_cv, batch_size=batch_size, epochs=epochs, validation_data=(x_valid_cv, y_valid_cv), shuffle=True)\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    scores.append(score[1] * 100)\n",
    "print(\"average accuracy: %.2f%% (+/- %.2f%%)\" % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"models/model5x5.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"models/model5x5.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
